import os
import multiprocessing as mp
from utils import *
import argparse
from test import test
import torch
import sys
import importlib.util
from pathlib import Path
from test import test
from utils import parse_dataset_args, parse_global_args, parse_train_args, parse_test_args
from logger_utils import get_logger
logger = get_logger(__name__)
logger.info("==== QT_Mob runner started ====")

# å¼€å…³
TRAIN = False
TEST = True
CUDA_VISIBLE_DEVICES = "0,1,2,3"  # âœ… å•è¿›ç¨‹åªä½¿ç”¨ä¸€ä¸ªGPU
PATH_TO_SFT_SAVE_DIR = "checkpoints"
# ä½ çš„ train.py è·¯å¾„ï¼ˆä¼˜å…ˆç”¨é¡¹ç›®å†…çš„ï¼Œè‹¥ä¸å­˜åœ¨åˆ™ç”¨ä¸Šä¼ çš„ï¼‰
TRAIN_SCRIPT_PATH = "QT_Mob_main/train.py"
# if not Path(TRAIN_SCRIPT_PATH).exists() and Path("/mnt/data/train.py").exists():
#     TRAIN_SCRIPT_PATH = "/mnt/data/train.py"

def import_train_module(train_script_path: str):
    """åŠ¨æ€å¯¼å…¥ train.py æ–‡ä»¶"""
    try:
        spec = importlib.util.spec_from_file_location("qt_mob_train", train_script_path)
        if spec is None or spec.loader is None:
            raise ImportError(f"æ— æ³•ä» {train_script_path} å¯¼å…¥ train.py")
        mod = importlib.util.module_from_spec(spec)
        sys.modules["qt_mob_train"] = mod
        spec.loader.exec_module(mod)
        logger.info(f"âœ… æˆåŠŸå¯¼å…¥è®­ç»ƒè„šæœ¬: {train_script_path}")
        return mod
    except Exception:
        logger.exception(f"âŒ å¯¼å…¥ {train_script_path} å¤±è´¥")
        raise

def train_model_trl(args):
    """å•è¿›ç¨‹ç›´æ¥è°ƒç”¨ train.py çš„ main(args)"""
    try:
        train_mod = import_train_module(TRAIN_SCRIPT_PATH)
        if not hasattr(train_mod, "main"):
            raise AttributeError(f"{TRAIN_SCRIPT_PATH} ä¸­æœªæ‰¾åˆ° main(args) å‡½æ•°")
        logger.info(f"å¼€å§‹å•è¿›ç¨‹è®­ç»ƒ: {TRAIN_SCRIPT_PATH}::main(args)")
        train_mod.main(args)
        logger.info("âœ… å•è¿›ç¨‹è®­ç»ƒå®Œæˆã€‚")
    except Exception:
        logger.exception("âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        raise

def test_model(args):
    """æ‰§è¡Œæµ‹è¯•"""
    try:
        args.ckpt_path = f"{args.path_to_sft_save_dir}/{args.experiment_name}"
        if args.test_task == "seq":
            args.results_file = f"{args.path_to_sft_save_dir}/{args.experiment_name}/test_results.json"
        elif args.test_task == "recovery":
            args.results_file = f"{args.path_to_sft_save_dir}/{args.experiment_name}/test_results_rec.json"

        logger.info(f"å¼€å§‹æµ‹è¯•ä»»åŠ¡: {args.test_task}")
        test(args)
        logger.info(f"âœ… æµ‹è¯•ä»»åŠ¡ {args.test_task} å®Œæˆï¼Œç»“æœæ–‡ä»¶: {args.results_file}")
    except Exception:
        logger.exception("âŒ æµ‹è¯•é˜¶æ®µå‡ºé”™")
        raise


def choose_model(base_model):
    """é€‰æ‹©æ¨¡å‹è·¯å¾„"""
    mapping = {
        "3.2": "path to Llama-3.2-1B-Instruct",
        "3.1": "path to Llama-3.1-8B-Instruct",
        "tiny": "path to TinyLlama_v1.1",
        "qwen": "Qwen3-8B",
        "phi": "path to phi-1_5",
        "olmo": "path to OLMo-1B-0724-hf",
    }
    if base_model not in mapping:
        logger.error(f"Unknown base model: {base_model}")
        raise NotImplementedError(f"Unknown base model: {base_model}")
    logger.info(f"Base model '{base_model}' é€‰æ‹©è·¯å¾„: {mapping[base_model]}")
    return mapping[base_model]


if __name__ == "__main__":

    parser = argparse.ArgumentParser(description='QT_Mob')
    parser = parse_dataset_args(parser)
    parser = parse_global_args(parser)
    parser = parse_train_args(parser)
    parser = parse_test_args(parser)
    args = parser.parse_args()

    # ==============================
    # å‚æ•°é…ç½®æ—¥å¿—
    # ==============================
    TEST_METRICS = "hit@1,hit@5,hit@10,ndcg@5,ndcg@10"
    args.path_to_sft_save_dir = PATH_TO_SFT_SAVE_DIR
    args.metrics = TEST_METRICS


    os.environ["CUDA_VISIBLE_DEVICES"] = CUDA_VISIBLE_DEVICES
    logger.info(f"CUDA_VISIBLE_DEVICES = {CUDA_VISIBLE_DEVICES}")

    BASE_MODEL = "qwen"
    args.base_model = "./Qwen3-8B"  # æœ¬åœ°æ¨¡å‹è·¯å¾„
    args.index_file = "data/h3_emb/location.index.json"
    DATASET_PATH = "./zdc_h3_index"

    TRAIN_TASKS = ["recovery","index","location",]
    TEST_TASK = "seq"
    CUSTOM_NAME = "tokyo_latest"

    args.tasks = ",".join(TRAIN_TASKS)
    args.data_path = DATASET_PATH
    args.experiment_name = BASE_MODEL + "_" + CUSTOM_NAME
    # args.num_workers=8
    # args.parallel_backend="process"
    # å¸ƒå°”å¼€å…³
    # æŠŠè¿™äº›æ”¹æˆ True/Falseï¼ˆä¸åŠ å¼•å·ï¼‰
    args.indexing   = True
    args.multi_seq  = True
    args.add_profile= True
    args.multi_rec  = True
    args.single_rec = True

    args.epochs = 2

    logger.info(f"è®­ç»ƒä»»åŠ¡: {args.tasks} | æµ‹è¯•ä»»åŠ¡: {TEST_TASK}")
    logger.info(f"æ•°æ®è·¯å¾„: {args.data_path}")
    logger.info(f"å®éªŒåç§°: {args.experiment_name}")
    logger.info(f"æ¨¡å‹: {args.base_model}")

    # ==============================
    # è®­ç»ƒä¸æµ‹è¯•æµç¨‹
    # ==============================
    try:
        if TRAIN:
            logger.info("ğŸš€ å¼€å§‹å•è¿›ç¨‹è®­ç»ƒæµç¨‹")
            train_model_trl(args)

        if TEST:
            for task in TEST_TASK.split(","):
                args.test_task = task
                logger.info(f"ğŸ§ª å¼€å§‹æµ‹è¯•ä»»åŠ¡: {task}")
                test_model(args)

        torch.cuda.empty_cache()
        logger.info("âœ… æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼ŒGPUç¼“å­˜å·²é‡Šæ”¾ã€‚")

    except Exception:
        logger.exception("âŒ Runner ä¸»æµç¨‹æ‰§è¡Œå¤±è´¥ã€‚")
        raise